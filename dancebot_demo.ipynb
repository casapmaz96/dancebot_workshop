{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING A DANCING ROBOT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Detecting Human Poses #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step is to set up the human pose detection model, which is the trt_pose model that can be found here: https://github.com/NVIDIA-AI-IOT/trt_pose . This model is already trained on millions of human pose images, so we will not train it in this workshop. We will only load it onto the Dancebot.\n",
    "\n",
    "1. Run the code cell below to load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the human pose keypoints\n",
    "import json\n",
    "import trt_pose.coco\n",
    "import trt_pose.models\n",
    "import torch\n",
    "\n",
    "with open('human_pose.json', 'r') as f:\n",
    "    human_pose = json.load(f)\n",
    "\n",
    "topology = trt_pose.coco.coco_category_to_topology(human_pose)\n",
    "\n",
    "num_parts = len(human_pose['keypoints'])\n",
    "num_links = len(human_pose['skeleton'])\n",
    "\n",
    "#Load the pose detection model\n",
    "import torch2trt\n",
    "from torch2trt import TRTModule\n",
    "OPTIMIZED_MODEL = 'resnet18_baseline_att_224x224_A_epoch_249_trt_2.pth'\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load(OPTIMIZED_MODEL))\n",
    "\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import PIL.Image\n",
    "import time\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda()\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def preprocess(image):\n",
    "    global device\n",
    "    device = torch.device('cuda')\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device)\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "from trt_pose.draw_objects import DrawObjects\n",
    "from trt_pose.parse_objects import ParseObjects\n",
    "\n",
    "parse_objects = ParseObjects(topology)\n",
    "draw_objects = DrawObjects(topology)\n",
    "\n",
    "def get_keypoints(image, human_pose, topology, object_counts, objects, normalized_peaks):\n",
    "    \"\"\"Get the keypoints from torch data and put into a dictionary where keys are keypoints\n",
    "    and values the x,y coordinates. The coordinates will be interpreted on the image given.\n",
    "\n",
    "    Args:\n",
    "        image: cv2 image\n",
    "        human_pose: json formatted file about the keypoints\n",
    "\n",
    "    Returns:\n",
    "        dictionary: dictionary where keys are keypoints and values are the x,y coordinates\n",
    "    \"\"\"\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    keypoints = {}\n",
    "    K = topology.shape[0]\n",
    "    count = int(object_counts[0])\n",
    "\n",
    "    for i in range(count):\n",
    "        obj = objects[0][i]\n",
    "        C = obj.shape[0]\n",
    "        for j in range(C):\n",
    "            k = int(obj[j])\n",
    "            if k >= 0:\n",
    "                peak = normalized_peaks[0][j][k]\n",
    "                x = round(float(peak[1]) * width)\n",
    "                y = round(float(peak[0]) * height)\n",
    "                keypoints[human_pose[\"keypoints\"][j]] = (x, y)\n",
    "\n",
    "    return keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will turn on the camera of the Dancebot.\n",
    "\n",
    "2. Run the cell below to turn the camera on. The camera's light should turn on if this step was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetcam.usb_camera import USBCamera\n",
    "\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import traceback\n",
    "\n",
    "\n",
    "camera = USBCamera(width=640, height=480, capture_fps=30)\n",
    "\n",
    "camera.running = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will view what the Dancebot sees and detects using the camera and the human pose detection model.\n",
    "\n",
    "3. Run the cell below. This will set up a window for viewing what the Dancebot sees. An empty frame should appear if this step was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2daa0dbcaa04b3fa3818ad660a1ac40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "from torchvision import transforms as trans\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def execute(change):\n",
    "    \n",
    "    global pose, reward, action, location, prevstate\n",
    "    #print(pose)\n",
    "    image = change['new']\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    diff = width - height\n",
    "\n",
    "    image = image[:, int(diff/2):height+int(diff/2), :]\n",
    "    resized_img = cv2.resize(image, dsize=(224, 224))\n",
    "    data = preprocess(resized_img)\n",
    "\n",
    "    \n",
    "    cmap, paf = model_trt(data)\n",
    "\n",
    "    cmap, paf = cmap.detach().cpu(), paf.detach().cpu()\n",
    "\n",
    "    counts, objects, peaks = parse_objects(cmap, paf)\n",
    "    \n",
    "    draw_objects(resized_img, counts, objects, peaks)\n",
    "\n",
    "    resized_img = cv2.resize(resized_img, dsize=(480, 480))\n",
    "    \n",
    "    image_w.value = bgr8_to_jpeg(resized_img[:, ::-1, :])\n",
    "\n",
    "\n",
    "image_w = ipywidgets.Image(format='jpeg')\n",
    "reward = 0\n",
    "\n",
    "location = 1\n",
    "pose = 0\n",
    "action = None\n",
    "prevstate = None\n",
    "display(image_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the exciting part!\n",
    "\n",
    "4. Run the cell below to play what the Dancebot sees on the frame above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. When you are done viewing, you can run the cell below to stop viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Teaching the robot how to Dance #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to decide on the dance rules. \n",
    "\n",
    "The dancebot will learn based on trial and error. Each human pose will make the robot perform a particular dance move. When the robot does the wrong move, it will receive punishment points. When it does the right move it will receive reward points. By doing a lot of attempts the robot will eventually learn how to maximize the reward points and minimize the punishment points.\n",
    "\n",
    "You can train the robot to dance in different behaviours. For example, you can encourage the robot to continue dancing when you're not performing any poses by punishing the robot for being still. You can also make sure the dance moves are not repetitive by punishing the robot for performing the same dance move twice in a row.\n",
    "\n",
    "1. Run the cell below to define reward and punishment points for the dancebot. Boxes will appear where you can enter your desired reward/punishment values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slide the buttons to your desired values. We recommend trying it with the default values first.\n",
      "Reward for the right dance move:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979e17c51caf4fb09bdd71325f75ea30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=100, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punishment for the wrong dance move:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27a107fe2ea346eba8d155301b103fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=500, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punishment for being still:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6496357f689e437e9bed561212cf5e70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punishment for the repeating the last move:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308b52523b6f4acda7b825ce7efde285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, max=500)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "rightDanceReward = widgets.IntSlider(\n",
    "    value=100,\n",
    "    min=0,\n",
    "    max=500,\n",
    "    step=1,\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "wrongDancePunishment = widgets.IntSlider(\n",
    "    value=500,\n",
    "    min=0,\n",
    "    max=500,\n",
    "    step=1,\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "stillnessPunishment = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=500,\n",
    "    step=1,\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "repetitivenessPunishment = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=500,\n",
    "    step=1,\n",
    "    description='',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "print('Slide the buttons to your desired values. We recommend trying it with the default values first.')\n",
    "print('Reward for the right dance move:')\n",
    "display(rightDanceReward)\n",
    "print('Punishment for the wrong dance move:')\n",
    "display(wrongDancePunishment)\n",
    "print('Punishment for being still:')\n",
    "display(stillnessPunishment)\n",
    "print('Punishment for the repeating the last move:')\n",
    "display(repetitivenessPunishment)\n",
    "#print(rightDanceReward.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally load the dancing AI model and train it to dance correctly based on the rules we defined above.\n",
    "\n",
    "2. Run the cell below to load the dancing AI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Carrier board is not from a Jetson Developer Kit.\n",
      "WARNNIG: Jetson.GPIO library has not been verified with this carrier board,\n",
      "WARNING: and in fact is unlikely to work correctly.\n"
     ]
    }
   ],
   "source": [
    "#Initialize robot for performing moves\n",
    "from robot import Robot\n",
    "import numpy as np\n",
    "dancebot = Robot()\n",
    "\n",
    "#Initialize AI model and dance session to start training\n",
    "from qlearning_agent_v2 import QLearningAgent\n",
    "\n",
    "danceAgent = QLearningAgent()\n",
    "danceAgent.epsilon = 0.3\n",
    "danceAgent.qvalues = np.zeros((16, 4))\n",
    "from dance_session_v2 import DanceSession\n",
    "sesh = DanceSession(danceAgent, wrongDancePunishment.value, stillnessPunishment.value,\n",
    "                rightDanceReward.value, repetitivenessPunishment.value, [(0, 'doNothing'), (1, 'wiggle'), (2, 'shuffle'), (3, 'donut')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create another view to see what the Dancebot sees again. We will use this to make sure the dancebot can see us when we try to train it.\n",
    "\n",
    "3. Run the cell below to set up a window for viewing what the Dancebot sees. An empty frame should appear if this step was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74656f74c9e41f8bde266a05c22ebe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms as trans\n",
    "import numpy as np\n",
    "import cv2\n",
    "runtime = 0\n",
    "def execute(change):\n",
    "    global runtime\n",
    "    image = change['new']\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "    diff = width - height\n",
    "\n",
    "    image = image[:, int(diff/2):height+int(diff/2), :]\n",
    "    resized_img = cv2.resize(image, dsize=(224, 224))\n",
    "    data = preprocess(resized_img)\n",
    "\n",
    "    \n",
    "    cmap, paf = model_trt(data)\n",
    "\n",
    "    cmap, paf = cmap.detach().cpu(), paf.detach().cpu()\n",
    "\n",
    "    counts, objects, peaks = parse_objects(cmap, paf)#, cmap_threshold=0.15, link_threshold=0.15)\n",
    "\n",
    "    \n",
    "    location = 0 if counts.item() > 0 else 1\n",
    "    draw_objects(resized_img, counts, objects, peaks)\n",
    "\n",
    "    resized_img = cv2.resize(resized_img, dsize=(480, 480))\n",
    "    runtime += 1\n",
    "    if runtime % 10 == 0:\n",
    "        kp = get_keypoints(resized_img, human_pose, topology, counts, objects, peaks)\n",
    "        sesh.run(counts, kp, dancebot)\n",
    "        runtime = 0\n",
    "    image_w.value = bgr8_to_jpeg(resized_img[:, ::-1, :])\n",
    "    \n",
    "    \n",
    "image_w = ipywidgets.Image(format='jpeg')\n",
    "reward = 0\n",
    "\n",
    "location = 1\n",
    "pose = 0\n",
    "action = None\n",
    "prevstate = None\n",
    "display(image_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dance session begins here! When you run the cell below the AI model will start watching you and trying different dance moves based on what poses you perform! Every time it does a wrong move, it will receive a punishment as you defined. Every time it does a right move, it will receive a reward as you defined. With trial and error, it will learn how to dance correctly based on the rules you defined.\n",
    "\n",
    "Poses you should do:\n",
    "\n",
    "-Arms down: neutral pose, the robot should do nothing\n",
    "\n",
    "-Left hand up: the robot should wiggle side to side\n",
    "\n",
    "-Right hand up: the robot should shuffle back and forth\n",
    "\n",
    "-Both hands up: the robot should spin\n",
    "\n",
    "The Dancebot will remember everything it learns by filling a table of environment states and robot actions. A very simple dancing robot would have a table like this:\n",
    "\n",
    "<img src=\"example.png\" width=\"400\" />\n",
    "\n",
    "Our Dancebot is more sophisticated: in addition to the human poses it sees it also remembers the previous dance move it performed so that it can be trained to not be repetitive. So an example environment state for our Dancebot would be [Pose: Arms down, Previous dance move: Wiggle] \n",
    "\n",
    "As you train the Dancebot, it will update the zeros in the table with the punishments and rewards it earns. When you are finished with the training it will start to pick and perform the highest reward action from this table given a pose.\n",
    "\n",
    "4. Run the cell below to start training the Dancebot by dancing with it!\n",
    "\n",
    "Tip: the robot only looks at your poses between performing dance moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. When you are done viewing and training, you can run the cell below to stop viewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Dancing with the fully trained Dancebot #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you are happy with your training, you can dance with the fully trained Dancebot. You can choose to dance with the robot you trained or some readily available fully trained Dancebots with different behaviours.\n",
    "\n",
    "You can choose:\n",
    "\n",
    "-My Dancebot: the Dancebot that you trained.\n",
    "\n",
    "-Restless Dancebot: a Dancebot trained to perform random, nonrepetitive dance moves if it doesn't see any poses other than the neutral pose.\n",
    "\n",
    "-Calm Dancebot: a Dancebot trained to only perform dance moves based on the poses it sees.\n",
    "\n",
    "1. Run the cell below to choose a Dancebot variation to dance with. It should create a dropdown menu upon successful execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a078519c0642a69e9d2e3a655137af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Dancebot:', index=2, options=('My Dancebot', 'Restless Dancebot', 'Calm Dancebot'), valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create ipywidget for selection\n",
    "dancebot_choice = ipywidgets.Dropdown(\n",
    "    options=['My Dancebot', 'Restless Dancebot', 'Calm Dancebot'],\n",
    "    value='Calm Dancebot',\n",
    "    description='Dancebot:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "display(dancebot_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run the cell below to set up a window for viewing what the Dancebot sees. An empty frame should appear if this step was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347d720d660642d5bb961001a466cae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#load selected dancebot\n",
    "danceAgent.epsilon = 0\n",
    "danceAgent.qvalues = danceAgent.variations[dancebot_choice.value]\n",
    "\n",
    "# copy paste of execute from above\n",
    "runtime = 0    \n",
    "image_w = ipywidgets.Image(format='jpeg')\n",
    "display(image_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Run the cell below to start dancing with the Dancebot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run the cell below to end the dance session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Questions and Experiments #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You completed a successful dance session with the Dancebot!\n",
    "\n",
    "Here are some questions about how the Dancebot learns and perceives the world. You can discuss these with your friends and ask them to the workshop instructors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the minimum amount of information that the robot needs to know about the environment to be a calm Dancebot?\n",
    "\n",
    "Hint: The poses only rely on arms being up or down, so does the dancebot need to know about the background, or where the legs are?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How would you make an even less repetitive version of the Dancebot that doesn't repeat any dance move for any 3 consecutive dance moves?\n",
    "\n",
    "Hint: What information does the robot need to make sure it doesn't do the same dance move that it performed 1 dance move ago? What about 2 dance moves ago? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. What reward and punishment configuration would you use to train a restless Dancebot? You can scroll up and try different reward/punishment values and train your bot again."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
